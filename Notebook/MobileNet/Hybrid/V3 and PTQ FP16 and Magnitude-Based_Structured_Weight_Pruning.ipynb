{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49829195-f171-498b-820c-da331f7aefdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\tf_pruning_clean\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5121b26-4a8f-489c-93fc-7c7c9de9db8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path SavedModel FP32 (baseline)\n",
    "SAVED_MODEL_DIR = \"D:/KULIAH/SEMESTER 7/Skripsi/Dataset/Pruning/mobilenetv3Large_trashnet_pruned_20-30-40\"\n",
    "\n",
    "# Output TFLite FP16\n",
    "TFLITE_FP16_PATH = \"D:/KULIAH/SEMESTER 7/Skripsi/Dataset/Final/pruned-mobilenetv3_large_fp16.tflite\"\n",
    "\n",
    "# Dataset test\n",
    "TEST_DIR = \"D:/KULIAH/SEMESTER 7/Skripsi/Dataset/Dataset_TrashNet_Final/test\"\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 1   # Konsisten untuk benchmarking inferensi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bd8a6c1-f2a7-4152-b86b-c18917fa2973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 383 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "num_classes = test_generator.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe64b70e-b8d1-41ca-98a2-107be1cf19f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proses Quantization PTQ FP16\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL_DIR)\n",
    "\n",
    "# Aktifkan optimisasi\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# FP16 quantization\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "\n",
    "# Konversi\n",
    "tflite_fp16_model = converter.convert()\n",
    "\n",
    "# Simpan model\n",
    "with open(TFLITE_FP16_PATH, \"wb\") as f:\n",
    "    f.write(tflite_fp16_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db4e8d48-2cf2-451d-b37a-c24b8da1f34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukuran model FP16: 5.85 MB\n"
     ]
    }
   ],
   "source": [
    "# Ukuran Model\n",
    "model_size_fp16 = os.path.getsize(TFLITE_FP16_PATH) / (1024 * 1024)\n",
    "print(f\"Ukuran model FP16: {model_size_fp16:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5628f34-8073-4490-a3af-28d023bd0eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TFLite Interpreter\n",
    "interpreter = tf.lite.Interpreter(model_path=TFLITE_FP16_PATH)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4fc9359-63d3-48f4-983d-2081e486c7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluasi Inferensi (Waktu & Prediksi)\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(len(test_generator)):\n",
    "    x_batch, y_batch = test_generator[i]\n",
    "\n",
    "    interpreter.set_tensor(input_details[0]['index'], x_batch)\n",
    "    interpreter.invoke()\n",
    "\n",
    "    output = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "    y_true.append(np.argmax(y_batch))\n",
    "    y_pred.append(np.argmax(output))\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09bafdca-4d13-4bbe-84e6-05378da3f174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Report (FP16)\n",
      "Total inference time  : 3.6152 detik\n",
      "Rata-rata per gambar  : 0.009439 detik\n"
     ]
    }
   ],
   "source": [
    "# Laporan Waktu Inferensi\n",
    "total_time = end_time - start_time\n",
    "avg_inference_time = total_time / len(test_generator)\n",
    "\n",
    "print(\"Time Report (FP16)\")\n",
    "print(f\"Total inference time  : {total_time:.4f} detik\")\n",
    "print(f\"Rata-rata per gambar  : {avg_inference_time:.6f} detik\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaba95f4-754d-4bca-84cc-360a6c479f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (FP16)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   cardboard       0.93      0.85      0.89        61\n",
      "       glass       0.83      0.92      0.88        76\n",
      "       metal       0.86      0.87      0.86        62\n",
      "       paper       0.88      0.90      0.89        90\n",
      "     plastic       0.83      0.82      0.83        72\n",
      "       trash       0.82      0.64      0.72        22\n",
      "\n",
      "    accuracy                           0.86       383\n",
      "   macro avg       0.86      0.83      0.84       383\n",
      "weighted avg       0.86      0.86      0.86       383\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report\n",
    "print(\"Classification Report (FP16)\")\n",
    "print(\n",
    "    classification_report(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        target_names=list(test_generator.class_indices.keys())\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_pruning_clean)",
   "language": "python",
   "name": "tf_pruning_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
