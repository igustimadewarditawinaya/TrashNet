{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb7e98b2-9b5a-4c6b-bae6-dd54474d82c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\tf_pruning_clean\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "781265b3-b413-45ce-9b09-0f9e2aa2708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS_FINE_TUNE = 10\n",
    "\n",
    "BASE_MODEL_PATH = \"D:/KULIAH/SEMESTER 7/Skripsi/Dataset/mobilenetv3Large_trashnet_base\"\n",
    "PRUNED_MODEL_PATH = \"D:/KULIAH/SEMESTER 7/Skripsi/Dataset/Pruning/mobilenetv3Large_trashnet_pruned_40\"\n",
    "\n",
    "DATASET_DIR = \"D:/KULIAH/SEMESTER 7/Skripsi/Dataset/Dataset_TrashNet_Final\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8266983-b1b8-4ad4-8c9b-d194e6412175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2001 images belonging to 6 classes.\n",
      "Found 377 images belonging to 6 classes.\n",
      "Found 383 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# DATA GENERATOR (RESCALE ONLY)\n",
    "train_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "val_test_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_data = train_gen.flow_from_directory(\n",
    "    os.path.join(DATASET_DIR, \"train\"),\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_data = val_test_gen.flow_from_directory(\n",
    "    os.path.join(DATASET_DIR, \"val\"),\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_data = val_test_gen.flow_from_directory(\n",
    "    os.path.join(DATASET_DIR, \"test\"),\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e6cfdf1-da26-4ddb-a936-174182cd62f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNGSI CEK UKURAN MODEL\n",
    "def get_model_size_mb(model_path):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(model_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            total_size += os.path.getsize(fp)\n",
    "    return total_size / (1024 * 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e03018cc-73c2-4b0b-8df7-9dcb8e8c23a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\tf_pruning_clean\\lib\\site-packages\\tf_keras\\src\\saving\\legacy\\saved_model\\load.py:109: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\tf_pruning_clean\\lib\\site-packages\\tf_keras\\src\\engine\\functional.py:156: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\tf_pruning_clean\\lib\\site-packages\\tf_keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " MobilenetV3large (Function  (None, 7, 7, 960)         2996352   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 960)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                61504     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3058246 (11.67 MB)\n",
      "Trainable params: 61894 (241.77 KB)\n",
      "Non-trainable params: 2996352 (11.43 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.models.load_model(\n",
    "    BASE_MODEL_PATH,\n",
    "    compile=False\n",
    ")\n",
    "\n",
    "base_model.compile(\n",
    "    optimizer=Adam(1e-4),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a57bdf0-c988-4383-8d2b-50259f007d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukuran Base Model      : 16.03 MB\n"
     ]
    }
   ],
   "source": [
    "# CEK UKURAN BASE MODEL\n",
    "base_model_size = get_model_size_mb(BASE_MODEL_PATH)\n",
    "print(f\"Ukuran Base Model      : {base_model_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "980b7df0-e02f-4050-9302-9c652515646f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pruning(model, initial_sparsity, final_sparsity, end_step):\n",
    "\n",
    "    pruning_params = {\n",
    "        \"pruning_schedule\": tfmot.sparsity.keras.PolynomialDecay(\n",
    "            initial_sparsity=initial_sparsity,\n",
    "            final_sparsity=final_sparsity,\n",
    "            begin_step=0,\n",
    "            end_step=end_step\n",
    "        )\n",
    "    }\n",
    "\n",
    "    def prune_layer(layer):\n",
    "        if isinstance(layer, tf.keras.layers.DepthwiseConv2D):\n",
    "            return layer\n",
    "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "            return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n",
    "        return layer\n",
    "\n",
    "    return tf.keras.models.clone_model(\n",
    "        model,\n",
    "        clone_function=prune_layer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1146015-41f9-4f98-ace8-994fc4f50cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = np.ceil(train_data.samples / BATCH_SIZE)\n",
    "end_step = int(steps_per_epoch * EPOCHS_FINE_TUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "779df7ba-3673-4c33-899d-e7a6d543dfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\tf_pruning_clean\\lib\\site-packages\\tensorflow\\python\\autograph\\converters\\directives.py:126: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\tf_pruning_clean\\lib\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "63/63 [==============================] - 56s 372ms/step - loss: 0.1668 - accuracy: 0.9680 - val_loss: 0.4236 - val_accuracy: 0.8488\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 16s 246ms/step - loss: 0.1504 - accuracy: 0.9720 - val_loss: 0.4269 - val_accuracy: 0.8515\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 16s 252ms/step - loss: 0.1407 - accuracy: 0.9745 - val_loss: 0.4229 - val_accuracy: 0.8541\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 16s 247ms/step - loss: 0.1301 - accuracy: 0.9790 - val_loss: 0.4038 - val_accuracy: 0.8568\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 16s 251ms/step - loss: 0.1199 - accuracy: 0.9805 - val_loss: 0.4103 - val_accuracy: 0.8541\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 16s 247ms/step - loss: 0.1112 - accuracy: 0.9835 - val_loss: 0.4090 - val_accuracy: 0.8515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x1977fd731c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_model = apply_pruning(base_model, 0.0, 0.40, end_step)\n",
    "\n",
    "pruned_model.compile(\n",
    "    optimizer=Adam(1e-4),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "    EarlyStopping(patience=2, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "pruned_model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=EPOCHS_FINE_TUNE,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f8c15e0-c087-4dd7-ba3d-770d85cb1fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pruned_model = tfmot.sparsity.keras.strip_pruning(pruned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51722669-a25a-48c5-89df-2251f4979200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: D:/KULIAH/SEMESTER 7/Skripsi/Dataset/Pruning/mobilenetv3Large_trashnet_pruned_40\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:/KULIAH/SEMESTER 7/Skripsi/Dataset/Pruning/mobilenetv3Large_trashnet_pruned_40\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pruning berhasil disimpan\n"
     ]
    }
   ],
   "source": [
    "final_pruned_model.save(\n",
    "    PRUNED_MODEL_PATH,\n",
    "    save_format=\"tf\"\n",
    ")\n",
    "\n",
    "print(\"Model pruning berhasil disimpan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd0d32fc-ee78-42ec-b4c4-83e6b9fe4e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukuran Pruned Model    : 15.55 MB\n",
      "Compression Ratio     : 1.03x\n",
      "Size Reduction        : 2.94%\n"
     ]
    }
   ],
   "source": [
    "# CEK UKURAN MODEL SETELAH PRUNING\n",
    "pruned_model_size = get_model_size_mb(PRUNED_MODEL_PATH)\n",
    "print(f\"Ukuran Pruned Model    : {pruned_model_size:.2f} MB\")\n",
    "\n",
    "compression_ratio = base_model_size / pruned_model_size\n",
    "size_reduction = (1 - (pruned_model_size / base_model_size)) * 100\n",
    "\n",
    "print(f\"Compression Ratio     : {compression_ratio:.2f}x\")\n",
    "print(f\"Size Reduction        : {size_reduction:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d6a33cf-c2bf-406c-99ed-03961379099d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 10s 210ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.84      0.88        61\n",
      "           1       0.82      0.87      0.85        76\n",
      "           2       0.83      0.85      0.84        62\n",
      "           3       0.86      0.89      0.87        90\n",
      "           4       0.81      0.83      0.82        72\n",
      "           5       0.82      0.64      0.72        22\n",
      "\n",
      "    accuracy                           0.85       383\n",
      "   macro avg       0.85      0.82      0.83       383\n",
      "weighted avg       0.85      0.85      0.85       383\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[51  1  0  8  0  1]\n",
      " [ 0 66  5  0  5  0]\n",
      " [ 0  3 53  4  2  0]\n",
      " [ 4  0  1 80  4  1]\n",
      " [ 0  7  4  0 60  1]\n",
      " [ 0  3  1  1  3 14]]\n"
     ]
    }
   ],
   "source": [
    "test_data.reset()\n",
    "\n",
    "predictions = final_pruned_model.predict(test_data)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_true = test_data.classes\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa694902-0e9b-40c9-8ee5-e54a76d2874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_inference(model, data_gen, warmup=3, runs=10):\n",
    "    \"\"\"\n",
    "    model      : stripped pruned model\n",
    "    data_gen   : test_data (shuffle=False)\n",
    "    warmup     : jumlah warmup run\n",
    "    runs       : jumlah benchmark run\n",
    "    \"\"\"\n",
    "\n",
    "    # Ambil 1 batch data\n",
    "    x_batch, _ = next(data_gen)\n",
    "\n",
    "    # Warm-up (penting untuk TensorFlow)\n",
    "    for _ in range(warmup):\n",
    "        _ = model.predict(x_batch, verbose=0)\n",
    "\n",
    "    times = []\n",
    "\n",
    "    for _ in range(runs):\n",
    "        start = time.time()\n",
    "        _ = model.predict(x_batch, verbose=0)\n",
    "        end = time.time()\n",
    "        times.append(end - start)\n",
    "\n",
    "    avg_time = np.mean(times)\n",
    "    per_image_time = avg_time / x_batch.shape[0]\n",
    "\n",
    "    print(\"Inference Benchmark\")\n",
    "    print(f\"Batch size         : {x_batch.shape[0]}\")\n",
    "    print(f\"Avg batch time     : {avg_time:.4f} seconds\")\n",
    "    print(f\"Avg per image time : {per_image_time:.6f} seconds\")\n",
    "\n",
    "    return avg_time, per_image_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5dafc80-4a59-4ce4-b84e-d34e845b8c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Benchmark\n",
      "Batch size         : 32\n",
      "Avg batch time     : 0.2544 seconds\n",
      "Avg per image time : 0.007950 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.254407262802124, 0.007950226962566375)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_inference(final_pruned_model, test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_pruning_clean)",
   "language": "python",
   "name": "tf_pruning_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
