{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7f10dd8-b90c-4e81-9f76-8bbfb52081a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\tf_pruning_clean\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dc91c57-a73b-489c-851e-e11cba06e8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS_FINE_TUNE = 10\n",
    "\n",
    "BASE_MODEL_PATH = \"D:/KULIAH/SEMESTER 7/Skripsi/Dataset/mobilenetv3Large_trashnet_base\"\n",
    "PRUNED_MODEL_PATH = \"D:/KULIAH/SEMESTER 7/Skripsi/Dataset/Pruning/mobilenetv3Large_trashnet_pruned_20-30-40\"\n",
    "\n",
    "DATASET_DIR = \"D:/KULIAH/SEMESTER 7/Skripsi/Dataset/Dataset_TrashNet_Final\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a7700ec-0aca-47ae-867d-83d6e4c758ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2001 images belonging to 6 classes.\n",
      "Found 377 images belonging to 6 classes.\n",
      "Found 383 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# DATA GENERATOR (RESCALE ONLY)\n",
    "train_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "val_test_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_data = train_gen.flow_from_directory(\n",
    "    os.path.join(DATASET_DIR, \"train\"),\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_data = val_test_gen.flow_from_directory(\n",
    "    os.path.join(DATASET_DIR, \"val\"),\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_data = val_test_gen.flow_from_directory(\n",
    "    os.path.join(DATASET_DIR, \"test\"),\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2cf8189-a3c8-4b19-b04f-7fd58d2b7416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNGSI CEK UKURAN MODEL\n",
    "def get_model_size_mb(model_path):\n",
    "    total_size = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(model_path):\n",
    "        for f in filenames:\n",
    "            fp = os.path.join(dirpath, f)\n",
    "            total_size += os.path.getsize(fp)\n",
    "    return total_size / (1024 * 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ef344fa-69c0-458d-bb3d-bba7533d7162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\tf_pruning_clean\\lib\\site-packages\\tf_keras\\src\\saving\\legacy\\saved_model\\load.py:109: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\tf_pruning_clean\\lib\\site-packages\\tf_keras\\src\\engine\\functional.py:156: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\tf_pruning_clean\\lib\\site-packages\\tf_keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " MobilenetV3large (Function  (None, 7, 7, 960)         2996352   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 960)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                61504     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3058246 (11.67 MB)\n",
      "Trainable params: 61894 (241.77 KB)\n",
      "Non-trainable params: 2996352 (11.43 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.models.load_model(\n",
    "    BASE_MODEL_PATH,\n",
    "    compile=False\n",
    ")\n",
    "\n",
    "base_model.compile(\n",
    "    optimizer=Adam(1e-4),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcfad06e-7c52-4467-980e-1d9d839fbaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukuran Base Model      : 16.03 MB\n"
     ]
    }
   ],
   "source": [
    "# CEK UKURAN BASE MODEL\n",
    "base_model_size = get_model_size_mb(BASE_MODEL_PATH)\n",
    "print(f\"Ukuran Base Model      : {base_model_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9038fac-2064-4c91-80c7-acf2e69c940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pruning(model, initial_sparsity, final_sparsity, end_step):\n",
    "\n",
    "    pruning_params = {\n",
    "        \"pruning_schedule\": tfmot.sparsity.keras.PolynomialDecay(\n",
    "            initial_sparsity=initial_sparsity,\n",
    "            final_sparsity=final_sparsity,\n",
    "            begin_step=0,\n",
    "            end_step=end_step\n",
    "        )\n",
    "    }\n",
    "\n",
    "    def prune_layer(layer):\n",
    "        if isinstance(layer, tf.keras.layers.DepthwiseConv2D):\n",
    "            return layer\n",
    "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "            return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n",
    "        return layer\n",
    "\n",
    "    return tf.keras.models.clone_model(\n",
    "        model,\n",
    "        clone_function=prune_layer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96731b2b-31df-4634-8fd4-fe74cf729093",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = np.ceil(train_data.samples / BATCH_SIZE)\n",
    "end_step = int(steps_per_epoch * EPOCHS_FINE_TUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e789b336-1e5b-41ab-b9e7-87724993cc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\tf_pruning_clean\\lib\\site-packages\\tensorflow\\python\\autograph\\converters\\directives.py:126: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\tf_pruning_clean\\lib\\site-packages\\tf_keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "63/63 [==============================] - 51s 300ms/step - loss: 0.1667 - accuracy: 0.9645 - val_loss: 0.4290 - val_accuracy: 0.8462\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 11s 181ms/step - loss: 0.1505 - accuracy: 0.9730 - val_loss: 0.4223 - val_accuracy: 0.8515\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 11s 182ms/step - loss: 0.1401 - accuracy: 0.9760 - val_loss: 0.4147 - val_accuracy: 0.8541\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 12s 183ms/step - loss: 0.1285 - accuracy: 0.9800 - val_loss: 0.4106 - val_accuracy: 0.8541\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 12s 184ms/step - loss: 0.1192 - accuracy: 0.9815 - val_loss: 0.4067 - val_accuracy: 0.8541\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 11s 181ms/step - loss: 0.1113 - accuracy: 0.9855 - val_loss: 0.4054 - val_accuracy: 0.8568\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 11s 181ms/step - loss: 0.1036 - accuracy: 0.9860 - val_loss: 0.3990 - val_accuracy: 0.8568\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 11s 181ms/step - loss: 0.0968 - accuracy: 0.9905 - val_loss: 0.4047 - val_accuracy: 0.8541\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 11s 182ms/step - loss: 0.0896 - accuracy: 0.9910 - val_loss: 0.4096 - val_accuracy: 0.8515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x27daf031c90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_model = apply_pruning(base_model, 0.0, 0.20, end_step)\n",
    "\n",
    "pruned_model.compile(\n",
    "    optimizer=Adam(1e-4),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "    EarlyStopping(patience=2, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "pruned_model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=EPOCHS_FINE_TUNE,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b105efd7-271b-43ff-ac96-2abd378df661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "63/63 [==============================] - 34s 293ms/step - loss: 0.0984 - accuracy: 0.9875 - val_loss: 0.4040 - val_accuracy: 0.8568\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 11s 180ms/step - loss: 0.0894 - accuracy: 0.9900 - val_loss: 0.4000 - val_accuracy: 0.8594\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 11s 181ms/step - loss: 0.0824 - accuracy: 0.9915 - val_loss: 0.3944 - val_accuracy: 0.8621\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 11s 180ms/step - loss: 0.0763 - accuracy: 0.9950 - val_loss: 0.3919 - val_accuracy: 0.8594\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 11s 180ms/step - loss: 0.0711 - accuracy: 0.9965 - val_loss: 0.4004 - val_accuracy: 0.8568\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 12s 183ms/step - loss: 0.0660 - accuracy: 0.9970 - val_loss: 0.3982 - val_accuracy: 0.8621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x27daefabd00>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_model = apply_pruning(pruned_model, 0.20, 0.30, end_step)\n",
    "\n",
    "pruned_model.compile(\n",
    "    optimizer=Adam(1e-4),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "pruned_model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=EPOCHS_FINE_TUNE,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d23a00db-9a0f-403c-b540-f364ff080b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "63/63 [==============================] - 34s 303ms/step - loss: 0.0727 - accuracy: 0.9960 - val_loss: 0.3963 - val_accuracy: 0.8647\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 11s 180ms/step - loss: 0.0657 - accuracy: 0.9955 - val_loss: 0.3951 - val_accuracy: 0.8594\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 11s 180ms/step - loss: 0.0602 - accuracy: 0.9970 - val_loss: 0.4103 - val_accuracy: 0.8515\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 11s 180ms/step - loss: 0.0559 - accuracy: 0.9975 - val_loss: 0.3950 - val_accuracy: 0.8647\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 11s 180ms/step - loss: 0.0517 - accuracy: 0.9980 - val_loss: 0.4024 - val_accuracy: 0.8674\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 11s 181ms/step - loss: 0.0478 - accuracy: 0.9980 - val_loss: 0.4093 - val_accuracy: 0.8594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x27d9d554490>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_model = apply_pruning(pruned_model, 0.30, 0.40, end_step)\n",
    "\n",
    "pruned_model.compile(\n",
    "    optimizer=Adam(1e-4),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "pruned_model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=EPOCHS_FINE_TUNE,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c83c9ece-26af-437e-8ea3-77ef497454fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pruned_model = tfmot.sparsity.keras.strip_pruning(pruned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8ab6a35-69bb-4de4-b5b5-be32d0f16951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: D:/KULIAH/SEMESTER 7/Skripsi/Dataset/Pruning/mobilenetv3Large_trashnet_pruned_20-30-40\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: D:/KULIAH/SEMESTER 7/Skripsi/Dataset/Pruning/mobilenetv3Large_trashnet_pruned_20-30-40\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model pruning berhasil disimpan\n"
     ]
    }
   ],
   "source": [
    "final_pruned_model.save(\n",
    "    PRUNED_MODEL_PATH,\n",
    "    save_format=\"tf\"\n",
    ")\n",
    "\n",
    "print(\"Model pruning berhasil disimpan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a52b9fb-d5f3-445a-90de-76426447eed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukuran Pruned Model    : 15.55 MB\n",
      "Compression Ratio     : 1.03x\n",
      "Size Reduction        : 2.94%\n"
     ]
    }
   ],
   "source": [
    "# CEK UKURAN MODEL SETELAH PRUNING\n",
    "pruned_model_size = get_model_size_mb(PRUNED_MODEL_PATH)\n",
    "print(f\"Ukuran Pruned Model    : {pruned_model_size:.2f} MB\")\n",
    "\n",
    "compression_ratio = base_model_size / pruned_model_size\n",
    "size_reduction = (1 - (pruned_model_size / base_model_size)) * 100\n",
    "\n",
    "print(f\"Compression Ratio     : {compression_ratio:.2f}x\")\n",
    "print(f\"Size Reduction        : {size_reduction:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48c798a4-d51f-41a5-97da-5ac0c9a3a5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 9s 153ms/step\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88        61\n",
      "           1       0.83      0.92      0.88        76\n",
      "           2       0.86      0.87      0.86        62\n",
      "           3       0.88      0.89      0.88        90\n",
      "           4       0.83      0.82      0.83        72\n",
      "           5       0.82      0.64      0.72        22\n",
      "\n",
      "    accuracy                           0.86       383\n",
      "   macro avg       0.86      0.83      0.84       383\n",
      "weighted avg       0.86      0.86      0.86       383\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[52  0  0  8  0  1]\n",
      " [ 0 70  3  0  3  0]\n",
      " [ 0  3 54  3  2  0]\n",
      " [ 5  0  1 80  3  1]\n",
      " [ 0  8  4  0 59  1]\n",
      " [ 0  3  1  0  4 14]]\n"
     ]
    }
   ],
   "source": [
    "test_data.reset()\n",
    "\n",
    "predictions = final_pruned_model.predict(test_data)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_true = test_data.classes\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66bd9875-b3b3-479a-951c-5e60b1292fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def benchmark_inference(model, data_gen, warmup=3, runs=10):\n",
    "    \"\"\"\n",
    "    model      : stripped pruned model\n",
    "    data_gen   : test_data (shuffle=False)\n",
    "    warmup     : jumlah warmup run\n",
    "    runs       : jumlah benchmark run\n",
    "    \"\"\"\n",
    "\n",
    "    # Ambil 1 batch data\n",
    "    x_batch, _ = next(data_gen)\n",
    "\n",
    "    # Warm-up (penting untuk TensorFlow)\n",
    "    for _ in range(warmup):\n",
    "        _ = model.predict(x_batch, verbose=0)\n",
    "\n",
    "    times = []\n",
    "\n",
    "    for _ in range(runs):\n",
    "        start = time.time()\n",
    "        _ = model.predict(x_batch, verbose=0)\n",
    "        end = time.time()\n",
    "        times.append(end - start)\n",
    "\n",
    "    avg_time = np.mean(times)\n",
    "    per_image_time = avg_time / x_batch.shape[0]\n",
    "\n",
    "    print(\"Inference Benchmark\")\n",
    "    print(f\"Batch size         : {x_batch.shape[0]}\")\n",
    "    print(f\"Avg batch time     : {avg_time:.4f} seconds\")\n",
    "    print(f\"Avg per image time : {per_image_time:.6f} seconds\")\n",
    "\n",
    "    return avg_time, per_image_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf63382d-cdf2-473c-a9e3-fbb380a863c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Benchmark\n",
      "Batch size         : 32\n",
      "Avg batch time     : 0.1957 seconds\n",
      "Avg per image time : 0.006116 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.19571435451507568, 0.006116073578596115)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_inference(final_pruned_model, test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_pruning_clean)",
   "language": "python",
   "name": "tf_pruning_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
